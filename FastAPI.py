import os
import logging
import time
import threading

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from slowapi import Limiter
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from llama_cpp import Llama
import nest_asyncio
import uvicorn

# ------------------------- ë¡œê·¸ ë””ë ‰í† ë¦¬ ë° ì„¤ì • -------------------------
LOG_DIR = "./logs"
os.makedirs(LOG_DIR, exist_ok=True)
log_file_path = os.path.join(LOG_DIR, "chat_server.log")

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(),  # ì½˜ì†” ë¡œê·¸
        logging.FileHandler(log_file_path, mode='a', encoding='utf-8')  # íŒŒì¼ ë¡œê·¸
    ]
)

# ------------------------- ë¡œì»¬ LLaMA ëª¨ë¸ ë¡œë”© -------------------------
MODEL_PATH = "./models/llama-2-7b-chat.Q4_K_M.gguf"  # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
logging.info("ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...")
llm = Llama(model_path=MODEL_PATH, n_ctx=2048)
logging.info("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

# ------------------------- FastAPI ì•± ì´ˆê¸°í™” ë° ì†ë„ ì œí•œ -------------------------
app = FastAPI()
limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter

@app.exception_handler(RateLimitExceeded)
async def rate_limit_handler(request: Request, exc: RateLimitExceeded):
    logging.warning(f"â›” ì†ë„ ì œí•œ ì´ˆê³¼: {request.client.host}")
    return JSONResponse(status_code=429, content={"error": "Too Many Requests"})

# ------------------------- CORS ì„¤ì • (Unity ë“± ì™¸ë¶€ ì ‘ê·¼ í—ˆìš©) -------------------------
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ------------------------- /chat API ì—”ë“œí¬ì¸íŠ¸ -------------------------
@app.post("/chat")
@limiter.limit("5/10seconds")  # IPë‹¹ 10ì´ˆì— ìµœëŒ€ 5íšŒ
async def chat(request: Request):
    try:
        data = await request.json()
        message = data.get("message", "").strip()

        if not message:
            return {"error": "ë©”ì‹œì§€ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."}

        logging.info(f"ğŸ“© ìš”ì²­ ìˆ˜ì‹ : {message}")
        prompt = f"[INST] {message} [/INST]"

        start_time = time.time()
        response = llm(prompt, max_tokens=256, stop=["</s>"], echo=False)
        elapsed = time.time() - start_time

        answer = response["choices"][0]["text"].strip()
        logging.info(f"âœ… ì‘ë‹µ ì™„ë£Œ ({elapsed:.2f}s): {answer[:60]}...")

        return {"response": answer, "time_taken": round(elapsed, 2)}

    except Exception as e:
        logging.exception("âŒ ì—ëŸ¬ ë°œìƒ")
        return JSONResponse(status_code=500, content={"error": str(e)})

# ------------------------- ì„œë²„ ì‹¤í–‰ (Jupyter ëŒ€ì‘ í¬í•¨) -------------------------
nest_asyncio.apply()

def run():
    uvicorn.run(app, host="0.0.0.0", port=8000)

threading.Thread(target=run, daemon=True).start()
